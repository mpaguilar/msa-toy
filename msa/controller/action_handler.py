"""Action handler for the multi-step agent controller."""

import logging
from typing import Dict, Any
from langchain_core.utils.json import parse_json_markdown

from msa.controller.models import ActionSelection
from msa.tools.base import ToolInterface

log = logging.getLogger(__name__)


def process_action_selection(
    thoughts: str,
    action_client: Any,
    action_prompt: Any,
    tools: Dict[str, ToolInterface]
) -> ActionSelection:
    """Select the next action based on generated thoughts.
    
    Args:
        thoughts: The thoughts generated by the think() method
        action_client: The LLM client for action selection
        action_prompt: The prompt template for action selection
        tools: Dictionary of available tools
        
    Returns:
        An ActionSelection object representing the chosen action
    """
    _msg = f"process_action_selection starting with thoughts: {thoughts}"
    log.debug(_msg)
    
    try:
        # Get available tools
        available_tools = ", ".join(tools.keys())
        
        # Generate action selection using the action LLM
        prompt = action_prompt.format(
            tools=available_tools,
            analysis=thoughts
        )
        
        response = action_client.call(prompt)
        
        # Handle different response types from the mock
        if hasattr(response, 'content'):
            response_text = response.content
        elif isinstance(response, str):
            response_text = response
        else:
            # For Mock objects or other types, convert to string
            response_text = str(response)
        
        # Parse the response
        action_dict = parse_json_markdown(response_text)
        action_selection = ActionSelection(**action_dict)
        
    except Exception as e:
        _msg = f"Error in action selection, using fallback: {e}"
        log.exception(_msg)
        # Fallback to web search if LLM fails
        action_selection = ActionSelection(
            action_type="tool",
            action_name="web_search",
            reasoning=f"Error in LLM action selection: {str(e)}",
            confidence=0.5
        )
    
    _msg = "process_action_selection returning"
    log.debug(_msg)
    return action_selection
