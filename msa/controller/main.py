"""Main controller implementation for the multi-step agent."""

import logging
from typing import Dict, Any
from msa.config import load_app_config
from msa.llm.client import get_llm_client
from msa.memory.manager import WorkingMemoryManager
from msa.memory.models import WorkingMemory, ToolResponse
from msa.tools.base import ToolInterface
from msa.tools.web_search import WebSearchTool
from msa.tools.wikipedia import WikipediaTool
from msa.controller.models import ActionSelection, CompletionDecision

log = logging.getLogger(__name__)


class Controller:
    """Main controller that orchestrates the ReAct cycle for the multi-step agent."""

    def __init__(self) -> None:
        """Initialize controller with configured LLM client and tools."""
        _msg = "Controller.__init__ starting"
        log.debug(_msg)
        
        # Load configuration
        app_config = load_app_config()
        self.max_iterations = app_config.get("max_iterations", 10)
        
        # Initialize LLM clients for different purposes
        self.thinking_client = get_llm_client("quick-medium")
        self.action_client = get_llm_client("quick-medium")
        self.completion_client = get_llm_client("quick-medium")
        
        # Initialize memory manager
        self.memory_manager = WorkingMemoryManager()
        
        # Initialize tools
        self.tools: Dict[str, ToolInterface] = {
            "web_search": WebSearchTool(),
            "wikipedia": WikipediaTool()
        }
        
        _msg = "Controller.__init__ returning"
        log.debug(_msg)

    def process_query(self, query: str) -> str:
        """Process user query through ReAct cycle.
        
        Args:
            query: The original user query to process
            
        Returns:
            The final answer generated by the agent
        """
        _msg = f"Controller.process_query starting with query: {query}"
        log.debug(_msg)
        
        # Initialize working memory with the query
        self.memory_manager = WorkingMemoryManager(query)
        
        # Run the ReAct cycle
        for i in range(self.max_iterations):
            _msg = f"Controller.process_query iteration {i+1}"
            log.debug(_msg)
            
            # Think phase
            thought = self.think(self.memory_manager.memory)
            
            # Act phase
            action_selection = self.act(thought)
            
            # Check for completion
            completion = self.check_completion()
            if completion.is_complete:
                _msg = "Controller.process_query returning completed answer"
                log.debug(_msg)
                return completion.answer
            
            # Observe phase
            if action_selection.action_type == "tool_call":
                tool_response = self.execute_tool(action_selection.action_name, query)
                observation = self.observe(tool_response)
                self.memory_manager.add_observation({
                    "content": observation,
                    "source": action_selection.action_name,
                    "confidence": action_selection.confidence
                })
            else:
                _msg = "Controller.process_query returning - no valid action"
                log.debug(_msg)
                return "Unable to determine next action."
        
        _msg = "Controller.process_query returning - max iterations reached"
        log.debug(_msg)
        return "Reached maximum iterations without completing the task."

    def think(self, memory: WorkingMemory) -> str:
        """Generate thought based on current state.
        
        Args:
            memory: Current working memory state
            
        Returns:
            Generated thought as a string
        """
        _msg = "Controller.think starting"
        log.debug(_msg)
        
        # Create prompt for thinking
        prompt = f"""
        Analyze the following question and current state to generate a thought:
        
        Original Question: {memory.query_state.original_query}
        Current Facts: {memory.information_store.facts}
        Execution History: {memory.execution_history.actions_taken}
        
        Provide a thought that analyzes the current state and determines what information is needed next.
        """
        
        # Call LLM to generate thought
        response = self.thinking_client.call(prompt)
        thought = response.get("content", "No thought generated")
        
        _msg = "Controller.think returning"
        log.debug(_msg)
        return thought

    def act(self, thought: str) -> ActionSelection:
        """Select next action based on thought.
        
        Args:
            thought: The thought generated by the thinking process
            
        Returns:
            Selected action as an ActionSelection object
        """
        _msg = "Controller.act starting"
        log.debug(_msg)
        
        # Create prompt for action selection
        prompt = f"""
        Based on the following thought, select the next action:
        
        Thought: {thought}
        
        Available Actions:
        1. tool_call: Use a tool to gather information (web_search, wikipedia)
        2. finish: Complete the task with an answer
        
        Select the most appropriate action.
        """
        
        # In a real implementation, this would use a PydanticOutputParser
        # For now, we'll return a default action
        action = ActionSelection(
            action_type="tool_call",
            action_name="web_search",
            reasoning="Selected web search to gather more information",
            confidence=0.8
        )
        
        _msg = "Controller.act returning"
        log.debug(_msg)
        return action

    def observe(self, action_result: ToolResponse) -> str:
        """Process observation from action result.
        
        Args:
            action_result: The result from executing an action
            
        Returns:
            Processed observation as a string
        """
        _msg = "Controller.observe starting"
        log.debug(_msg)
        
        # Process the tool response into an observation
        observation = f"Observed: {action_result.content}"
        
        _msg = "Controller.observe returning"
        log.debug(_msg)
        return observation

    def check_completion(self) -> CompletionDecision:
        """Check if the task is complete.
        
        Returns:
            Completion decision as a CompletionDecision object
        """
        _msg = "Controller.check_completion starting"
        log.debug(_msg)
        
        # For now, we'll return a default completion decision
        # In a real implementation, this would use an LLM to determine completion
        completion = CompletionDecision(
            is_complete=False,
            answer="",
            confidence=0.0,
            reasoning="Task not yet complete",
            remaining_tasks=["Gather more information"]
        )
        
        _msg = "Controller.check_completion returning"
        log.debug(_msg)
        return completion

    def execute_tool(self, tool_name: str, query: str) -> ToolResponse:
        """Execute a tool by name.
        
        Args:
            tool_name: Name of the tool to execute
            query: Query/input for the tool
            
        Returns:
            Tool response from the executed tool
        """
        _msg = f"Controller.execute_tool starting with tool: {tool_name}"
        log.debug(_msg)
        
        # Execute the tool if it exists
        if tool_name in self.tools:
            response = self.tools[tool_name].execute(query)
            _msg = "Controller.execute_tool returning"
            log.debug(_msg)
            return response
        else:
            # Return an error response if tool not found
            response = ToolResponse(
                content=f"Error: Tool '{tool_name}' not found",
                metadata={"error": True},
                raw_response={}
            )
            _msg = "Controller.execute_tool returning with error"
            log.debug(_msg)
            return response
