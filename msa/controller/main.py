"""Main controller implementation for the multi-step agent."""

import logging
from typing import Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser

from msa.config import load_app_config
from msa.llm.client import get_llm_client
from msa.memory.manager import WorkingMemoryManager
from msa.memory.models import WorkingMemory, ToolResponse
from msa.tools.base import ToolInterface
from msa.tools.web_search import WebSearchTool
from msa.tools.wikipedia import WikipediaTool
from msa.controller.models import ActionSelection, CompletionDecision
from msa.orchestration.synthesis import SynthesisEngine

log = logging.getLogger(__name__)


class Controller:
    """Main controller that orchestrates the ReAct cycle for the multi-step agent."""

    def __init__(self) -> None:
        """Initialize controller with configured LLM client and tools."""
        _msg = "Controller.__init__ starting"
        log.debug(_msg)
        
        # Load configuration
        app_config = load_app_config()
        self.max_iterations = app_config.get("max_iterations", 10)
        
        # Initialize LLM clients for different purposes
        self.thinking_client = get_llm_client("quick-medium")
        self.action_client = get_llm_client("tool-big")
        self.completion_client = get_llm_client("quick-medium")
        
        # Initialize tools
        self.tools: Dict[str, ToolInterface] = {
            "web_search": WebSearchTool(),
            "wikipedia": WikipediaTool()
        }
        
        # Initialize synthesis engine
        self.synthesis_engine = SynthesisEngine()
        
        # Initialize prompt templates
        self.think_prompt = PromptTemplate.from_template(
            "You are an AI assistant using the ReAct framework to answer questions.\n"
            "Analyze the question and current state to determine the next step.\n\n"
            "Question: {question}\n"
            "Current working memory:\n{memory_summary}\n\n"
            "Provide your analysis of what information is needed and what should be done next."
        )
        
        self.action_prompt = PromptTemplate.from_template(
            "Based on the analysis, select the next action to take.\n"
            "Available tools: {tools}\n\n"
            "Analysis: {analysis}\n\n"
            "{format_instructions}\n"
            "Respond with a valid ActionSelection JSON object."
        )
        
        self.completion_prompt = PromptTemplate.from_template(
            "Determine if we have sufficient information to answer the original question.\n\n"
            "Original question: {question}\n"
            "Collected information:\n{collected_info}\n\n"
            "{format_instructions}\n"
            "Respond with a valid CompletionDecision JSON object."
        )
        
        _msg = "Controller.__init__ returning"
        log.debug(_msg)

    def process_query(self, query: str) -> str:
        """Process user query through ReAct cycle.
        
        Args:
            query: The original user query to process
            
        Returns:
            The final answer generated by the agent
        """
        _msg = f"Controller.process_query starting with query: {query}"
        log.debug(_msg)
        
        # Initialize working memory with the query
        self.memory_manager = WorkingMemoryManager(query)
        
        # Run the ReAct cycle
        for i in range(self.max_iterations):
            _msg = f"Controller.process_query iteration {i+1}"
            log.debug(_msg)
            
            # Think phase
            thought = self.think(query, self.memory_manager)
            
            # Act phase
            action_selection = self.act(thought)
            
            # Check for completion
            completion = self.check_completion(query, self.memory_manager)
            if completion.is_complete:
                # Synthesize final answer
                synthesis_result = self.synthesis_engine.synthesize_answer(self.memory_manager.memory)
                final_answer = synthesis_result["answer"]
                
                _msg = "Controller.process_query returning completed answer"
                log.debug(_msg)
                return final_answer
            
            # Observe phase
            if action_selection.action_type == "tool":
                tool_response = self.execute_tool(action_selection.action_name, query)
                observation = self.observe(tool_response)
                self.memory_manager.add_observation({
                    "content": observation,
                    "source": action_selection.action_name,
                    "confidence": action_selection.confidence
                })
            else:
                _msg = "Controller.process_query returning - no valid action"
                log.debug(_msg)
                return "Unable to determine next action."
        
        _msg = "Controller.process_query returning - max iterations reached"
        log.debug(_msg)
        return "Reached maximum iterations without completing the task."

    def think(self, query: str, memory_manager: WorkingMemoryManager) -> str:
        """Generate thoughts based on the current state and memory.
        
        Args:
            query: The original query to process
            memory_manager: The working memory manager
            
        Returns:
            A string containing the generated thoughts
        """
        _msg = f"Controller.think starting with query: {query}"
        log.debug(_msg)
        
        # Get a summary of the current memory state
        memory_summary = memory_manager.serialize()
        
        # Generate thoughts using the thinking LLM
        prompt = self.think_prompt.format(
            question=query,
            memory_summary=memory_summary
        )
        
        response = self.thinking_client.call(prompt)
        
        _msg = "Controller.think returning"
        log.debug(_msg)
        return response.content

    def act(self, thoughts: str) -> ActionSelection:
        """Select the next action based on generated thoughts.
        
        Args:
            thoughts: The thoughts generated by the think() method
            
        Returns:
            An ActionSelection object representing the chosen action
        """
        _msg = f"Controller.act starting with thoughts: {thoughts}"
        log.debug(_msg)
        
        # Create output parser for ActionSelection
        parser = PydanticOutputParser(pydantic_object=ActionSelection)
        format_instructions = parser.get_format_instructions()
        
        # Get available tools
        available_tools = ", ".join(self.tools.keys())
        
        # Generate action selection using the action LLM
        prompt = self.action_prompt.format(
            tools=available_tools,
            analysis=thoughts,
            format_instructions=format_instructions
        )
        
        try:
            response = self.action_client.call(prompt, parser=parser)
            action = response.content
        except Exception as e:
            _msg = f"Error in action selection, using fallback: {e}"
            log.exception(_msg)
            # Fallback to web search if LLM fails
            action = ActionSelection(
                action_type="tool",
                action_name="web_search",
                reasoning=f"Error in LLM action selection: {str(e)}",
                confidence=0.5
            )
        
        _msg = "Controller.act returning"
        log.debug(_msg)
        return action

    def observe(self, action_result: ToolResponse) -> str:
        """Process observation from action result.
        
        Args:
            action_result: The result from executing an action
            
        Returns:
            Processed observation as a string
        """
        _msg = "Controller.observe starting"
        log.debug(_msg)
        
        # Process the tool response into an observation
        observation = f"Observed: {action_result.content}"
        
        _msg = "Controller.observe returning"
        log.debug(_msg)
        return observation

    def check_completion(self, query: str, memory_manager: WorkingMemoryManager) -> CompletionDecision:
        """Determine if we have sufficient information to answer the question.
        
        Args:
            query: The original query
            memory_manager: The working memory manager
            
        Returns:
            A CompletionDecision object indicating completion status
        """
        _msg = f"Controller.check_completion starting with query: {query}"
        log.debug(_msg)
        
        # Get collected information from memory
        memory = memory_manager.get_memory()
        collected_info = str(memory.information_store)
        
        # Create output parser for CompletionDecision
        parser = PydanticOutputParser(pydantic_object=CompletionDecision)
        format_instructions = parser.get_format_instructions()
        
        # Generate completion decision using the completion LLM
        prompt = self.completion_prompt.format(
            question=query,
            collected_info=collected_info,
            format_instructions=format_instructions
        )
        
        try:
            response = self.completion_client.call(prompt, parser=parser)
            decision = response.content
        except Exception as e:
            _msg = f"Error in completion check, using fallback: {e}"
            log.exception(_msg)
            # Fallback decision if LLM fails
            decision = CompletionDecision(
                is_complete=False,
                answer="",
                confidence=0.0,
                reasoning=f"Error in LLM completion check: {str(e)}",
                remaining_tasks=["Continue gathering information"]
            )
        
        _msg = "Controller.check_completion returning"
        log.debug(_msg)
        return decision

    def execute_tool(self, tool_name: str, query: str) -> ToolResponse:
        """Execute a tool by name.
        
        Args:
            tool_name: Name of the tool to execute
            query: Query/input for the tool
            
        Returns:
            Tool response from the executed tool
        """
        _msg = f"Controller.execute_tool starting with tool: {tool_name}"
        log.debug(_msg)
        
        # Execute the tool if it exists
        if tool_name in self.tools:
            response = self.tools[tool_name].execute(query)
            _msg = "Controller.execute_tool returning"
            log.debug(_msg)
            return response
        else:
            # Return an error response if tool not found
            response = ToolResponse(
                content=f"Error: Tool '{tool_name}' not found",
                metadata={"error": True},
                raw_response={}
            )
            _msg = "Controller.execute_tool returning with error"
            log.debug(_msg)
            return response
